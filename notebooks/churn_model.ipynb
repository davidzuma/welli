{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a2aff0f",
   "metadata": {},
   "source": [
    "# Churn Prediction Model\n",
    "\n",
    "This notebook creates a machine learning model to predict user churn risk based on behavioral features.\n",
    "\n",
    "**Churn Prediction Features:**\n",
    "- `days_since_signup`: Days since user signed up\n",
    "- `total_sessions`: Total number of sessions\n",
    "- `avg_session_duration`: Average session duration (minutes)\n",
    "- `streak_length`: Current streak length (days)\n",
    "- `last_login_days_ago`: Days since last login\n",
    "- `content_completion_rate`: Rate of content completion (0-1)\n",
    "- `notification_response_rate`: Response rate to notifications (0-1)\n",
    "- `goal_progress_percentage`: Progress towards goals (0-100)\n",
    "\n",
    "The trained model will be saved as `churn_model.joblib` for use by the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52138b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score, \n",
    "    precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    ")\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(\"Ready to build churn prediction model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf2d249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset\n",
    "data_path = \"../data/training_dataset.csv\"\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    print(\"❌ Training dataset not found!\")\n",
    "    print(\"Please run the data_creation.ipynb notebook first to generate the dataset.\")\n",
    "else:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"✅ Loaded dataset with {len(df):,} users\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Churn rate: {df['churn'].mean():.2%}\")\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322f7553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze churn distribution\n",
    "print(\"=== Churn Distribution Analysis ===\")\n",
    "\n",
    "churn_counts = df['churn'].value_counts()\n",
    "print(f\"Active users (0): {churn_counts[0]:,} ({churn_counts[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Churned users (1): {churn_counts[1]:,} ({churn_counts[1]/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Churn by user type\n",
    "print(\"\\nChurn by user type:\")\n",
    "churn_by_type = df.groupby('user_type')['churn'].agg(['count', 'sum', 'mean'])\n",
    "churn_by_type.columns = ['total_users', 'churned_users', 'churn_rate']\n",
    "churn_by_type['churn_rate'] = churn_by_type['churn_rate'].apply(lambda x: f\"{x:.1%}\")\n",
    "display(churn_by_type)\n",
    "\n",
    "# Visualize churn distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Overall churn distribution\n",
    "axes[0].bar(['Active', 'Churned'], churn_counts.values, color=['green', 'red'], alpha=0.7)\n",
    "axes[0].set_title('Overall Churn Distribution')\n",
    "axes[0].set_ylabel('Number of Users')\n",
    "for i, v in enumerate(churn_counts.values):\n",
    "    axes[0].text(i, v + 10, f'{v:,}\\n({v/len(df)*100:.1f}%)', ha='center')\n",
    "\n",
    "# Churn by user type\n",
    "user_type_churn = df.groupby(['user_type', 'churn']).size().unstack()\n",
    "user_type_churn.plot(kind='bar', stacked=True, color=['green', 'red'], alpha=0.7, ax=axes[1])\n",
    "axes[1].set_title('Churn Distribution by User Type')\n",
    "axes[1].set_xlabel('User Type')\n",
    "axes[1].set_ylabel('Number of Users')\n",
    "axes[1].legend(['Active', 'Churned'])\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014676dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare churn prediction features (exactly as defined in FeaturePreparator)\n",
    "churn_features = [\n",
    "    \"days_since_signup\",\n",
    "    \"total_sessions\", \n",
    "    \"avg_session_duration\",\n",
    "    \"streak_length\",\n",
    "    \"last_login_days_ago\",\n",
    "    \"content_completion_rate\",\n",
    "    \"notification_response_rate\",\n",
    "    \"goal_progress_percentage\"\n",
    "]\n",
    "\n",
    "X = df[churn_features].copy()\n",
    "y = df['churn'].copy()\n",
    "\n",
    "print(\"Churn prediction features:\")\n",
    "for i, feature in enumerate(churn_features, 1):\n",
    "    print(f\"  {i}. {feature}\")\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
    "print(f\"Target distribution: {y.value_counts().to_dict()}\")\n",
    "print(\"\\nFeature statistics:\")\n",
    "display(X.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c3206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature correlations with churn\n",
    "feature_churn_corr = df[churn_features + ['churn']].corr()['churn'].drop('churn').sort_values(key=abs, ascending=False)\n",
    "\n",
    "print(\"Feature correlations with churn:\")\n",
    "for feature, corr in feature_churn_corr.items():\n",
    "    direction = \"↑\" if corr > 0 else \"↓\"\n",
    "    print(f\"  {feature}: {corr:.3f} {direction}\")\n",
    "\n",
    "# Visualize correlations\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=feature_churn_corr.abs().values, y=feature_churn_corr.index, \n",
    "            palette=['red' if x > 0 else 'blue' for x in feature_churn_corr.values])\n",
    "plt.title('Feature Correlations with Churn (Absolute Values)')\n",
    "plt.xlabel('Absolute Correlation with Churn')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a03b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]:,} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]:,} samples\")\n",
    "print(f\"Training churn rate: {y_train.mean():.2%}\")\n",
    "print(f\"Test churn rate: {y_test.mean():.2%}\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\n✅ Features scaled successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dc2471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline Random Forest model\n",
    "print(\"Training baseline Random Forest model...\")\n",
    "\n",
    "rf_baseline = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'  # Handle class imbalance\n",
    ")\n",
    "\n",
    "rf_baseline.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_baseline = rf_baseline.predict(X_test_scaled)\n",
    "y_pred_proba_baseline = rf_baseline.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate baseline model\n",
    "print(\"\\n=== Baseline Model Performance ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_baseline):.3f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_baseline):.3f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_baseline):.3f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_baseline):.3f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_baseline):.3f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_baseline, target_names=['Active', 'Churned']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29dc28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning with GridSearchCV\n",
    "print(\"Performing hyperparameter tuning...\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 15, 20],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'min_samples_leaf': [2, 4]\n",
    "}\n",
    "\n",
    "rf_grid = RandomForestClassifier(\n",
    "    random_state=42, \n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    rf_grid, \n",
    "    param_grid, \n",
    "    cv=5, \n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\n✅ Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation ROC-AUC: {grid_search.best_score_:.3f}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "rf_final = grid_search.best_estimator_\n",
    "y_pred_final = rf_final.predict(X_test_scaled)\n",
    "y_pred_proba_final = rf_final.predict_proba(X_test_scaled)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bbb47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate final model\n",
    "print(\"=== Final Model Performance ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_final):.3f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_final):.3f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_final):.3f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_final):.3f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_final):.3f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_final, target_names=['Active', 'Churned']))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_final)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Cross-validation scores\n",
    "cv_scores = cross_val_score(rf_final, X_train_scaled, y_train, cv=5, scoring='roc_auc')\n",
    "print(f\"\\nCross-validation ROC-AUC: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24355d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': churn_features,\n",
    "    'importance': rf_final.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"=== Feature Importance ===\")\n",
    "display(feature_importance)\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feature_importance, x='importance', y='feature', palette='viridis')\n",
    "plt.title('Feature Importance for Churn Prediction')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Top 3 most important features\n",
    "top_features = feature_importance.head(3)\n",
    "print(f\"\\n🏆 Top 3 Most Important Features:\")\n",
    "for i, (_, row) in enumerate(top_features.iterrows(), 1):\n",
    "    print(f\"  {i}. {row['feature']}: {row['importance']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5ad6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba_final)\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba_final)\n",
    "axes[0,0].plot(fpr, tpr, label=f'ROC Curve (AUC = {auc_score:.3f})', color='blue')\n",
    "axes[0,0].plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "axes[0,0].set_xlabel('False Positive Rate')\n",
    "axes[0,0].set_ylabel('True Positive Rate')\n",
    "axes[0,0].set_title('ROC Curve')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True)\n",
    "\n",
    "# 2. Confusion Matrix Heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Active', 'Churned'], \n",
    "            yticklabels=['Active', 'Churned'], ax=axes[0,1])\n",
    "axes[0,1].set_title('Confusion Matrix')\n",
    "axes[0,1].set_ylabel('True Label')\n",
    "axes[0,1].set_xlabel('Predicted Label')\n",
    "\n",
    "# 3. Prediction Probability Distribution\n",
    "axes[1,0].hist(y_pred_proba_final[y_test==0], bins=20, alpha=0.7, label='Active Users', color='green')\n",
    "axes[1,0].hist(y_pred_proba_final[y_test==1], bins=20, alpha=0.7, label='Churned Users', color='red')\n",
    "axes[1,0].set_xlabel('Churn Probability')\n",
    "axes[1,0].set_ylabel('Count')\n",
    "axes[1,0].set_title('Churn Probability Distribution')\n",
    "axes[1,0].legend()\n",
    "\n",
    "# 4. Risk Level Distribution (matching application logic)\n",
    "risk_levels = []\n",
    "for prob in y_pred_proba_final:\n",
    "    if prob >= 0.7:\n",
    "        risk_levels.append(\"High\")\n",
    "    elif prob >= 0.4:\n",
    "        risk_levels.append(\"Medium\")\n",
    "    else:\n",
    "        risk_levels.append(\"Low\")\n",
    "\n",
    "risk_counts = pd.Series(risk_levels).value_counts()\n",
    "colors_risk = ['green', 'orange', 'red']\n",
    "axes[1,1].bar(risk_counts.index, risk_counts.values, color=colors_risk, alpha=0.7)\n",
    "axes[1,1].set_title('Risk Level Distribution')\n",
    "axes[1,1].set_ylabel('Number of Users')\n",
    "for i, v in enumerate(risk_counts.values):\n",
    "    axes[1,1].text(i, v + 5, str(v), ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Risk level thresholds (matching application logic):\")\n",
    "print(\"  • Low risk: < 0.4 churn probability\")\n",
    "print(\"  • Medium risk: 0.4 - 0.7 churn probability\") \n",
    "print(\"  • High risk: > 0.7 churn probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de55cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze model predictions by user type\n",
    "df_test = df.loc[X_test.index].copy()\n",
    "df_test['predicted_churn_prob'] = y_pred_proba_final\n",
    "df_test['predicted_churn'] = y_pred_final\n",
    "\n",
    "print(\"=== Model Performance by User Type ===\")\n",
    "\n",
    "for user_type in df_test['user_type'].unique():\n",
    "    subset = df_test[df_test['user_type'] == user_type]\n",
    "    actual_churn_rate = subset['churn'].mean()\n",
    "    predicted_churn_rate = subset['predicted_churn'].mean()\n",
    "    avg_churn_prob = subset['predicted_churn_prob'].mean()\n",
    "    \n",
    "    print(f\"\\n{user_type.title()} Users:\")\n",
    "    print(f\"  Sample size: {len(subset):,}\")\n",
    "    print(f\"  Actual churn rate: {actual_churn_rate:.1%}\")\n",
    "    print(f\"  Predicted churn rate: {predicted_churn_rate:.1%}\")\n",
    "    print(f\"  Average churn probability: {avg_churn_prob:.3f}\")\n",
    "    \n",
    "    # Calculate accuracy for this user type\n",
    "    accuracy = accuracy_score(subset['churn'], subset['predicted_churn'])\n",
    "    print(f\"  Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78750fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model and supporting data\n",
    "data_dir = \"../data\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Save churn prediction model\n",
    "churn_model_path = os.path.join(data_dir, \"churn_model.joblib\")\n",
    "joblib.dump(rf_final, churn_model_path)\n",
    "print(f\"✅ Saved churn model to {churn_model_path}\")\n",
    "\n",
    "# Save feature scaler\n",
    "churn_scaler_path = os.path.join(data_dir, \"churn_scaler.joblib\")\n",
    "joblib.dump(scaler, churn_scaler_path)\n",
    "print(f\"✅ Saved feature scaler to {churn_scaler_path}\")\n",
    "\n",
    "# Save feature importance\n",
    "feature_importance_path = os.path.join(data_dir, \"churn_feature_importance.csv\")\n",
    "feature_importance.to_csv(feature_importance_path, index=False)\n",
    "print(f\"✅ Saved feature importance to {feature_importance_path}\")\n",
    "\n",
    "# Save model metadata\n",
    "model_metadata = {\n",
    "    \"model_type\": \"RandomForestClassifier\",\n",
    "    \"feature_names\": churn_features,\n",
    "    \"n_features\": len(churn_features),\n",
    "    \"training_samples\": len(X_train),\n",
    "    \"test_samples\": len(X_test),\n",
    "    \"best_params\": grid_search.best_params_,\n",
    "    \"performance_metrics\": {\n",
    "        \"accuracy\": float(accuracy_score(y_test, y_pred_final)),\n",
    "        \"precision\": float(precision_score(y_test, y_pred_final)),\n",
    "        \"recall\": float(recall_score(y_test, y_pred_final)),\n",
    "        \"f1_score\": float(f1_score(y_test, y_pred_final)),\n",
    "        \"roc_auc\": float(roc_auc_score(y_test, y_pred_proba_final))\n",
    "    },\n",
    "    \"risk_thresholds\": {\n",
    "        \"low\": \"< 0.4\",\n",
    "        \"medium\": \"0.4 - 0.7\",\n",
    "        \"high\": \"> 0.7\"\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "metadata_path = os.path.join(data_dir, \"churn_model_metadata.json\")\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(model_metadata, f, indent=2)\n",
    "print(f\"✅ Saved model metadata to {metadata_path}\")\n",
    "\n",
    "print(f\"\\n🎉 Churn prediction model training completed successfully!\")\n",
    "print(f\"\\n📁 Files created:\")\n",
    "print(f\"   • {churn_model_path}\")\n",
    "print(f\"   • {churn_scaler_path}\")\n",
    "print(f\"   • {feature_importance_path}\")\n",
    "print(f\"   • {metadata_path}\")\n",
    "\n",
    "print(f\"\\n📈 Final Model Performance:\")\n",
    "print(f\"   • Algorithm: Random Forest with {rf_final.n_estimators} trees\")\n",
    "print(f\"   • Features: {len(churn_features)} behavioral features\")\n",
    "print(f\"   • Accuracy: {accuracy_score(y_test, y_pred_final):.3f}\")\n",
    "print(f\"   • ROC-AUC: {roc_auc_score(y_test, y_pred_proba_final):.3f}\")\n",
    "print(f\"   • Training samples: {len(X_train):,} users\")\n",
    "print(f\"   • Test samples: {len(X_test):,} users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8a4c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the saved model\n",
    "print(\"=== Testing Saved Model ===\")\n",
    "\n",
    "# Load the model\n",
    "loaded_churn_model = joblib.load(churn_model_path)\n",
    "loaded_scaler = joblib.load(churn_scaler_path)\n",
    "with open(metadata_path, 'r') as f:\n",
    "    loaded_metadata = json.load(f)\n",
    "\n",
    "print(\"✅ All models and metadata loaded successfully\")\n",
    "\n",
    "# Test with sample user data (matching the expected API format)\n",
    "test_users = [\n",
    "    {\n",
    "        \"name\": \"High-risk user\",\n",
    "        \"data\": {\n",
    "            \"days_since_signup\": 15,\n",
    "            \"total_sessions\": 3,\n",
    "            \"avg_session_duration\": 2.5,\n",
    "            \"streak_length\": 0,\n",
    "            \"last_login_days_ago\": 10,\n",
    "            \"content_completion_rate\": 0.2,\n",
    "            \"notification_response_rate\": 0.1,\n",
    "            \"goal_progress_percentage\": 15.0\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Low-risk user\",\n",
    "        \"data\": {\n",
    "            \"days_since_signup\": 120,\n",
    "            \"total_sessions\": 45,\n",
    "            \"avg_session_duration\": 12.0,\n",
    "            \"streak_length\": 15,\n",
    "            \"last_login_days_ago\": 1,\n",
    "            \"content_completion_rate\": 0.85,\n",
    "            \"notification_response_rate\": 0.75,\n",
    "            \"goal_progress_percentage\": 80.0\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"\\n🧪 Testing with sample users:\")\n",
    "\n",
    "for test_user in test_users:\n",
    "    # Prepare features (simulate FeaturePreparator logic)\n",
    "    test_features = np.array([\n",
    "        test_user[\"data\"][\"days_since_signup\"],\n",
    "        test_user[\"data\"][\"total_sessions\"],\n",
    "        test_user[\"data\"][\"avg_session_duration\"],\n",
    "        test_user[\"data\"][\"streak_length\"],\n",
    "        test_user[\"data\"][\"last_login_days_ago\"],\n",
    "        test_user[\"data\"][\"content_completion_rate\"],\n",
    "        test_user[\"data\"][\"notification_response_rate\"],\n",
    "        test_user[\"data\"][\"goal_progress_percentage\"]\n",
    "    ]).reshape(1, -1)\n",
    "    \n",
    "    # Scale features\n",
    "    test_features_scaled = loaded_scaler.transform(test_features)\n",
    "    \n",
    "    # Make prediction\n",
    "    churn_probability = loaded_churn_model.predict_proba(test_features_scaled)[0][1]\n",
    "    \n",
    "    # Determine risk level (matching application logic)\n",
    "    if churn_probability >= 0.7:\n",
    "        risk_level = \"high\"\n",
    "    elif churn_probability >= 0.4:\n",
    "        risk_level = \"medium\"\n",
    "    else:\n",
    "        risk_level = \"low\"\n",
    "    \n",
    "    print(f\"\\n{test_user['name']}:\")\n",
    "    print(f\"  Churn probability: {churn_probability:.3f}\")\n",
    "    print(f\"  Risk level: {risk_level}\")\n",
    "    print(f\"  Input features: {test_user['data']}\")\n",
    "\n",
    "print(f\"\\n✅ Model is working correctly and ready for production use!\")\n",
    "print(f\"\\n🔧 Model compatible with:\")\n",
    "print(f\"   • src/models/churn_model.py (ChurnPredictor)\")\n",
    "print(f\"   • src/utils/feature_prep.py (FeaturePreparator)\")\n",
    "print(f\"   • src/utils/model_loader.py (ModelLoader)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
